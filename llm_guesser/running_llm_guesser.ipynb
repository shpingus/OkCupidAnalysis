{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Gathering Data",
   "id": "ed8cb08ed211e001"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "8362b2835defa83b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from time import sleep\n",
    "\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "profiles_for_processing = pd.read_csv('../data/data_for_report/profiles_for_processing.csv').drop(columns=['Unnamed: 0'], errors='ignore')\n",
    "relevant_questions = pd.read_csv('../data/data_for_report/relevant_questions.csv')"
   ],
   "id": "7aaa3f93cd871dc1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# profiles_for_processing['id'] = profiles_for_processing.index\n",
    "rows, ages = profiles_for_processing.drop(['d_age'], axis=1, inplace=False), profiles_for_processing[['row_index', 'd_age']]"
   ],
   "id": "560b6e0792d25e57",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# profiles_for_processing['index']",
   "id": "b008207b06339a99",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Running predictions\n",
   "id": "bfd2884fb8d183c2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Retries + No Batching + Concurrent Gemini Flash 2.5",
   "id": "7803b03fe4ae8814"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def create_prompt(row: pd.Series) -> str:\n",
    "    prompt = f\"\"\"You are an expert demographic analyst tasked with predicting a person's age based on their survey responses and characteristics.\n",
    "\n",
    "    **Instructions:**\n",
    "    1. Analyze the provided information carefully\n",
    "    2. Consider patterns in responses, interests, values, and life circumstances\n",
    "    3. Provide a specific age estimate (as a number)\n",
    "    4. Give a brief explanation for your prediction\n",
    "    5. Be realistic - most online dating users are between 18-65 years old\n",
    "\n",
    "    **User Information:**\n",
    "    {row.to_dict()}\n",
    "\n",
    "    **Required Response Format (JSON):**\n",
    "    {{\n",
    "        \"predicted_age\": [number between 18-100],\n",
    "        \"confidence\": [number between 0.0-1.0],\n",
    "        \"explanation\": \"[brief explanation of reasoning]\"\n",
    "    }}\n",
    "\n",
    "    Questions you will receive answers to:\n",
    "    question,text,option_1,option_2,option_3,option_4,N,Type,Order,Keywords\n",
    "    q35,\"Regardless of future plans, what's more interesting to you right now?\",Sex,Love,,,50384,N,,sex/intimacy\n",
    "    q41,How important is religion/God in your life?,Extremely important,Somewhat important,Not very important,Not at all important,54140,O,,religion/superstition\n",
    "    q9688,Could you date someone who does drugs?,No,\"Yes, but only soft stuff like marijuana\",Yes,,55697,O,,preference\n",
    "    q16053,How willing are you to meet someone from OkCupid in person?,Totally willing!,\"Hesitant, but I'd certainly consider it.\",I'm not interested in meeting in person.,,58043,O,,preference\n",
    "    q20930,Rate your self-confidence:,\"Very, very high\",Higher than average,Average,Below average,53737,O,,descriptive\n",
    "    q35660,How often are you open with your feelings?,Always,Usually,Rarely,Never,49489,O,,descriptive\n",
    "    q41953,About how long do you want your next relationship to last?,One night,A few months to a year,Several years,The rest of my life,48614,O,,preference\n",
    "    q44639,Do you like scary movies?,Yes,No,,,54964,O,,preference\n",
    "    q179268,Are you either vegetarian or vegan?,Yes,No,,,54202,O,,politics; descriptive\n",
    "    q358077,Could you date someone who was really messy?,Yes,No,,,55695,O,,preference\n",
    "    d_religion_type,Religion type,,,,,66365,,,\n",
    "    d_drugs,Drugs,,,,,55697,,,\n",
    "    lf_want,Type of match,,,,,66365,,,\n",
    "\n",
    "    **Important:**\n",
    "    - Provide ONLY the JSON response, no additional text\n",
    "    - The predicted_age must be a specific number, not a range\n",
    "    - Confidence should reflect how certain you are (1.0 = very certain, 0.5 = moderate, 0.1 = uncertain)\"\"\"\n",
    "\n",
    "    return prompt"
   ],
   "id": "6ef6906730d72dc1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Function to run prediction for a single row\n",
    "def predict_single(row: pd.Series, model: str = \"gemini-2.5-flash\") -> dict:\n",
    "    retries = 6\n",
    "    while retries > 0:\n",
    "        try:\n",
    "            response = client.models.generate_content(\n",
    "                model=model,\n",
    "                contents=create_prompt(row),\n",
    "                config={\"response_mime_type\": \"application/json\"},\n",
    "            )\n",
    "            data = json.loads(response.text)\n",
    "            return {\n",
    "                \"row_index\": row[\"row_index\"],\n",
    "                \"predicted_age\": data.get(\"predicted_age\"),\n",
    "                \"confidence\": data.get(\"confidence\"),\n",
    "                \"explanation\": data.get(\"explanation\"),\n",
    "            }\n",
    "        except Exception as e:\n",
    "            retries -= 1\n",
    "            if retries == 0:\n",
    "                print(f\"⚠️ Failed for row {row['row_index']} after retries: {e}\")\n",
    "                return {\n",
    "                    \"row_index\": row[\"row_index\"],\n",
    "                    \"predicted_age\": None,\n",
    "                    \"confidence\": None,\n",
    "                    \"explanation\": f\"⚠️ Failed after retries: {e}\"\n",
    "                }\n",
    "            sleep(10)\n",
    "\n",
    "    print(f\"⚠️ Failed for row {row['row_index']} after running out of retries\")\n",
    "    return {\n",
    "            \"row_index\": row[\"row_index\"],\n",
    "            \"predicted_age\": None,\n",
    "            \"confidence\": None,\n",
    "            \"explanation\": f\"⚠️ Failed after running out of retries\"\n",
    "        }"
   ],
   "id": "cba5f0de0b674f9a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from google import genai\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm import tqdm\n",
    "from time import sleep\n",
    "\n",
    "# Initialize client\n",
    "client = genai.Client()\n",
    "\n",
    "# Load your dataframe\n",
    "# rows = pd.read_csv(\"...\")\n",
    "\n",
    "predictions = []\n",
    "with ThreadPoolExecutor(max_workers=5) as executor:  # tune max_workers depending on limits\n",
    "    futures = {executor.submit(predict_single, row): row[\"row_index\"] for _, row in rows.iterrows()}\n",
    "    for future in tqdm(as_completed(futures), total=len(futures), desc=\"Predicting ages\"):\n",
    "        predictions.append(future.result())\n",
    "\n",
    "predicted_ages = pd.DataFrame(predictions)"
   ],
   "id": "ba76ef5129f07eb7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Going over the failed ones with Gemini 2.5 Pro",
   "id": "eba00ab407a8c005"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "failed = merged[merged.explanation.str.contains('⚠️')]\n",
    "failed_rows = rows[rows.row_index.isin(failed.row_index)]\n",
    "\n",
    "\n",
    "retrying_predictions = []\n",
    "with ThreadPoolExecutor(max_workers=5) as executor:  # tune max_workers depending on limits\n",
    "    futures = {executor.submit(predict_single, row, \"gemini-2.5-flash\"): row[\"row_index\"] for _, row in failed_rows.iterrows()}\n",
    "    for future in tqdm(as_completed(futures), total=len(futures), desc=\"Predicting ages\"):\n",
    "        retrying_predictions.append(future.result())\n",
    "\n",
    "retrying_predicted_ages = pd.DataFrame(retrying_predictions)\n",
    "# predicted_ages.to_csv('../data/data_for_report/llm_predicted_ages_v3.csv', index=False)"
   ],
   "id": "5680bf0ae13d517c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Merging the results and saving",
   "id": "6665c4cbc52d5b06"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Step 1: Set 'row_index' as the index for both DataFrames\n",
    "predicted_ages.set_index('row_index', inplace=True)\n",
    "retrying_predicted_ages.set_index('row_index', inplace=True)\n",
    "\n",
    "# Step 2: Replace rows in predicted_ages with those from retrying_predicted_ages\n",
    "predicted_ages.update(retrying_predicted_ages)\n",
    "\n",
    "# Step 3 (optional): Reset index if you want 'row_index' back as a column\n",
    "predicted_ages.reset_index(inplace=True)\n",
    "predicted_ages"
   ],
   "id": "5f7240220f8c7573",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "merged = predicted_ages.merge(ages, on='row_index')\n",
    "merged['difference'] = (merged['predicted_age'] - merged['d_age']).abs()\n",
    "# merged.to_csv('../data/data_for_report/llm_predicted_ages_v3_with_diff.csv', index=False)"
   ],
   "id": "5748e3f2b98df70c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "merged.difference.describe()",
   "id": "aa7c7be24b6eba22",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Graphing",
   "id": "e1040cd9761b3dbd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df = merged.copy()",
   "id": "b4b04a027ebf8a57",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Graph 1",
   "id": "f8d29528b72bb2d9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = px.scatter(\n",
    "    merged,\n",
    "    x=\"d_age\",                # Real age\n",
    "    y=\"predicted_age\",        # Predicted age\n",
    "    color=\"confidence\",       # Confidence as color\n",
    "    color_continuous_scale=\"Viridis\",\n",
    "    hover_data=[\"row_index\", \"difference\", \"explanation\"],\n",
    "    labels={\n",
    "        \"d_age\": \"Real Age\",\n",
    "        \"predicted_age\": \"Predicted Age\",\n",
    "        \"confidence\": \"Confidence (0-1)\"\n",
    "    },\n",
    "    title=\"Predicted Age vs Real Age with Confidence Coloring\"\n",
    ")\n",
    "\n",
    "# Add y = x line to indicate perfect predictions\n",
    "fig.add_shape(\n",
    "    type=\"line\",\n",
    "    x0=merged['d_age'].min(),\n",
    "    y0=merged['d_age'].min(),\n",
    "    x1=merged['d_age'].max(),\n",
    "    y1=merged['d_age'].max(),\n",
    "    line=dict(color=\"gray\", dash=\"dash\"),\n",
    "    name=\"Perfect Prediction Line\"\n",
    ")\n",
    "\n",
    "# Final layout tweaks\n",
    "fig.update_layout(\n",
    "    width=800,\n",
    "    height=600,\n",
    "    legend_title_text='Confidence',\n",
    "    coloraxis_colorbar=dict(title=\"Confidence\"),\n",
    "    xaxis=dict(title=\"Real Age\"),\n",
    "    yaxis=dict(title=\"Predicted Age\"),\n",
    ")\n",
    "\n",
    "fig.show()"
   ],
   "id": "54b8516fed6a0366",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Graph 2",
   "id": "fc628dd6aea2083e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig = px.scatter(\n",
    "    merged,\n",
    "    x=\"d_age\",\n",
    "    y=\"difference\",\n",
    "    color=\"confidence\",\n",
    "    color_continuous_scale=\"RdYlGn\",\n",
    "    hover_data=[\"predicted_age\", \"row_index\", \"confidence\"],\n",
    "    labels={\n",
    "        \"d_age\": \"Real Age\",\n",
    "        \"difference\": \"Prediction Error (Predicted - Real)\",\n",
    "        \"confidence\": \"Confidence\"\n",
    "    },\n",
    "    title=\"Prediction Error vs Real Age (Colored by Confidence)\"\n",
    ")\n",
    "\n",
    "fig.add_hline(y=0, line_dash=\"dash\", line_color=\"gray\")\n",
    "\n",
    "fig.update_layout(\n",
    "    height=600,\n",
    "    width=900,\n",
    "    xaxis_title=\"Real Age\",\n",
    "    yaxis_title=\"Prediction Error (years)\",\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ],
   "id": "5aceb086b648d808",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Graph 3 - Smoothed Predicted vs Actual age",
   "id": "e73f00a26fab35eb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import kaleido\n",
    "\n",
    "# Copy and sample 200 rows if more than 200\n",
    "df_vis = df.copy()\n",
    "if len(df_vis) > 200:\n",
    "    df_vis = df_vis.sample(200, random_state=42).sort_values(\"row_index\" if \"row_index\" in df_vis.columns else None)\n",
    "\n",
    "df_vis.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Create bins of 5 rows (total 40 bins)\n",
    "bin_size = 5\n",
    "num_bins = len(df_vis) // bin_size\n",
    "\n",
    "# Truncate to multiple of 5\n",
    "df_vis = df_vis.iloc[:num_bins * bin_size]\n",
    "\n",
    "# Reshape and calculate mean per bin\n",
    "actual_binned = df_vis[\"d_age\"].values.reshape(-1, bin_size).mean(axis=1)\n",
    "predicted_binned = df_vis[\"predicted_age\"].values.reshape(-1, bin_size).mean(axis=1)\n",
    "\n",
    "# X-axis = bin indices (0 to 39)\n",
    "x = np.arange(num_bins)\n",
    "\n",
    "# Overall mean actual age\n",
    "mean_actual_age = df[\"d_age\"].mean()\n",
    "mean_line = [mean_actual_age] * num_bins\n",
    "\n",
    "# Build the figure\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add actual age line + markers\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=x,\n",
    "    y=actual_binned,\n",
    "    mode='lines+markers',\n",
    "    name='Avg Actual Age (per 5 pts)',\n",
    "    line=dict(color='blue'),\n",
    "    marker=dict(size=6)\n",
    "))\n",
    "\n",
    "# Add predicted age line + markers\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=x,\n",
    "    y=predicted_binned,\n",
    "    mode='lines+markers',\n",
    "    name='Avg Predicted Age (per 5 pts)',\n",
    "    line=dict(color='orange'),\n",
    "    marker=dict(size=6)\n",
    "))\n",
    "\n",
    "# Add overall mean actual age as dashed line\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=x,\n",
    "    y=mean_line,\n",
    "    mode='lines',\n",
    "    name=f'Overall Mean Actual Age ({mean_actual_age:.1f})',\n",
    "    line=dict(color='gray', dash='dash')\n",
    "))\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title='Smoothed Predicted vs Actual Age (40 Bins Averaging 5 Samples Each)',\n",
    "    xaxis_title='Bin Index (Each = 5 Samples)',\n",
    "    yaxis_title='Age',\n",
    "    legend_title='Legend',\n",
    "    template='plotly_white'\n",
    ")\n",
    "\n",
    "# Show the figure\n",
    "fig.show()"
   ],
   "id": "8603005a9947b3cc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Playground",
   "id": "d0f8fecbeaab70ad"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "4bbfc6b384182442",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig1 = px.scatter(\n",
    "    merged,\n",
    "    x=\"d_age\",\n",
    "    y=\"predicted_age\",\n",
    "    color=\"confidence\",\n",
    "    size=merged[\"confidence\"] ** 5 / 10,\n",
    "    hover_data=[\"row_index\", \"confidence\"],\n",
    "    labels={\n",
    "        \"d_age\": \"Actual Age\",\n",
    "        \"predicted_age\": \"Predicted Age\",\n",
    "        \"confidence\": \"Confidence\"\n",
    "    },\n",
    "    title=\"Predicted Age vs Actual Age Colored by Confidence\"\n",
    ")\n",
    "\n",
    "fig1.add_shape(\n",
    "    type=\"line\",\n",
    "    x0=merged[\"d_age\"].min(),\n",
    "    y0=merged[\"d_age\"].min(),\n",
    "    x1=merged[\"d_age\"].max(),\n",
    "    y1=merged[\"d_age\"].max(),\n",
    "    line=dict(color=\"gray\", dash=\"dash\"),\n",
    ")\n",
    "\n",
    "fig1.show()\n"
   ],
   "id": "6ab146fcf2465b56",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "corr = df['confidence'].corr(df['difference'])\n",
    "print(f'Correlation between confidence and difference: {corr}')\n"
   ],
   "id": "c608b0408a8aaf64",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "abs(df['d_age'] - 31.77).mean()",
   "id": "85f16d7d106996a0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for start in tqdm(range(0, len(rows), BATCH_SIZE), desc=\"Predicting ages in batches\"):\n",
    "    batch = rows.iloc[start:start+BATCH_SIZE]\n",
    "    print(batch)"
   ],
   "id": "9a7898000848daf3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "batch",
   "id": "903c4b3244f58871",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "response = client.models.generate_content(\n",
    "        model=\"gemini-2.5-flash-lite\",\n",
    "        contents=create_batch_prompt(batch),\n",
    "        config={\"response_mime_type\": \"application/json\"},\n",
    "    )\n"
   ],
   "id": "9682a130c4496ee5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "response",
   "id": "809e36845800310f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "try:\n",
    "    batch_results = json.loads(response.text)\n",
    "except Exception as e:\n",
    "    print(f\"⚠️ Error parsing batch {start}: {e}\")\n",
    "\n",
    "for res in batch_results:\n",
    "    idx = res.get(\"row_index\")\n",
    "    print({\n",
    "        \"row_index\": idx,\n",
    "        \"predicted_age\": res.get(\"predicted_age\"),\n",
    "        \"real_age\": ages.loc[idx],\n",
    "        \"confidence\": res.get(\"confidence\"),\n",
    "        \"explanation\": res.get(\"explanation\"),\n",
    "    })\n"
   ],
   "id": "44ce2127e6c45375",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "batch_results = json.loads(response.text)",
   "id": "ab9be2aa1c1b08ae",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "batch_results[0]",
   "id": "bd486d025f46695d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for res in batch_results:\n",
    "    idx = res.get(\"row_index\")\n",
    "    print({\n",
    "        \"row_index\": idx,\n",
    "        \"predicted_age\": res.get(\"predicted_age\"),\n",
    "        \"real_age\": ages.loc[idx],\n",
    "        \"confidence\": res.get(\"confidence\"),\n",
    "        \"explanation\": res.get(\"explanation\"),\n",
    "    })"
   ],
   "id": "e9836565349ae908",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "rows",
   "id": "4672705b174b427a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "9869eacf35a5a052",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
