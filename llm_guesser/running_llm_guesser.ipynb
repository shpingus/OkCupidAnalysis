{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Gathering Data",
   "id": "ed8cb08ed211e001"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "8362b2835defa83b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from time import sleep\n",
    "\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "profiles_for_processing = pd.read_csv('../data/data_for_report/profiles_for_processing.csv').drop(columns=['Unnamed: 0'], errors='ignore')\n",
    "relevant_questions = pd.read_csv('../data/data_for_report/relevant_questions.csv')"
   ],
   "id": "7aaa3f93cd871dc1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# profiles_for_processing['id'] = profiles_for_processing.index\n",
    "rows, ages = profiles_for_processing.drop(['d_age'], axis=1, inplace=False), profiles_for_processing[['row_index', 'd_age']]"
   ],
   "id": "560b6e0792d25e57",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# profiles_for_processing['index']",
   "id": "b008207b06339a99",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Running predictions\n",
   "id": "bfd2884fb8d183c2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Retries + No Batching + Concurrent Gemini Flash 2.5",
   "id": "7803b03fe4ae8814"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def create_prompt(row: pd.Series) -> str:\n",
    "    prompt = f\"\"\"You are an expert demographic analyst tasked with predicting a person's age based on their survey responses and characteristics.\n",
    "\n",
    "    **Instructions:**\n",
    "    1. Analyze the provided information carefully\n",
    "    2. Consider patterns in responses, interests, values, and life circumstances\n",
    "    3. Provide a specific age estimate (as a number)\n",
    "    4. Give a brief explanation for your prediction\n",
    "    5. Be realistic - most online dating users are between 18-65 years old\n",
    "\n",
    "    **User Information:**\n",
    "    {row.to_dict()}\n",
    "\n",
    "    **Required Response Format (JSON):**\n",
    "    {{\n",
    "        \"predicted_age\": [number between 18-100],\n",
    "        \"confidence\": [number between 0.0-1.0],\n",
    "        \"explanation\": \"[brief explanation of reasoning]\"\n",
    "    }}\n",
    "\n",
    "    Questions you will receive answers to:\n",
    "    question,text,option_1,option_2,option_3,option_4,N,Type,Order,Keywords\n",
    "    q35,\"Regardless of future plans, what's more interesting to you right now?\",Sex,Love,,,50384,N,,sex/intimacy\n",
    "    q41,How important is religion/God in your life?,Extremely important,Somewhat important,Not very important,Not at all important,54140,O,,religion/superstition\n",
    "    q9688,Could you date someone who does drugs?,No,\"Yes, but only soft stuff like marijuana\",Yes,,55697,O,,preference\n",
    "    q16053,How willing are you to meet someone from OkCupid in person?,Totally willing!,\"Hesitant, but I'd certainly consider it.\",I'm not interested in meeting in person.,,58043,O,,preference\n",
    "    q20930,Rate your self-confidence:,\"Very, very high\",Higher than average,Average,Below average,53737,O,,descriptive\n",
    "    q35660,How often are you open with your feelings?,Always,Usually,Rarely,Never,49489,O,,descriptive\n",
    "    q41953,About how long do you want your next relationship to last?,One night,A few months to a year,Several years,The rest of my life,48614,O,,preference\n",
    "    q44639,Do you like scary movies?,Yes,No,,,54964,O,,preference\n",
    "    q179268,Are you either vegetarian or vegan?,Yes,No,,,54202,O,,politics; descriptive\n",
    "    q358077,Could you date someone who was really messy?,Yes,No,,,55695,O,,preference\n",
    "    d_religion_type,Religion type,,,,,66365,,,\n",
    "    d_drugs,Drugs,,,,,55697,,,\n",
    "    lf_want,Type of match,,,,,66365,,,\n",
    "\n",
    "    **Important:**\n",
    "    - Provide ONLY the JSON response, no additional text\n",
    "    - The predicted_age must be a specific number, not a range\n",
    "    - Confidence should reflect how certain you are (1.0 = very certain, 0.5 = moderate, 0.1 = uncertain)\"\"\"\n",
    "\n",
    "    return prompt"
   ],
   "id": "6ef6906730d72dc1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Function to run prediction for a single row\n",
    "def predict_single(row: pd.Series, model: str = \"gemini-2.5-flash\") -> dict:\n",
    "    retries = 6\n",
    "    while retries > 0:\n",
    "        try:\n",
    "            response = client.models.generate_content(\n",
    "                model=model,\n",
    "                contents=create_prompt(row),\n",
    "                config={\"response_mime_type\": \"application/json\"},\n",
    "            )\n",
    "            data = json.loads(response.text)\n",
    "            return {\n",
    "                \"row_index\": row[\"row_index\"],\n",
    "                \"predicted_age\": data.get(\"predicted_age\"),\n",
    "                \"confidence\": data.get(\"confidence\"),\n",
    "                \"explanation\": data.get(\"explanation\"),\n",
    "            }\n",
    "        except Exception as e:\n",
    "            retries -= 1\n",
    "            if retries == 0:\n",
    "                print(f\"⚠️ Failed for row {row['row_index']} after retries: {e}\")\n",
    "                return {\n",
    "                    \"row_index\": row[\"row_index\"],\n",
    "                    \"predicted_age\": None,\n",
    "                    \"confidence\": None,\n",
    "                    \"explanation\": f\"⚠️ Failed after retries: {e}\"\n",
    "                }\n",
    "            sleep(10)\n",
    "\n",
    "    print(f\"⚠️ Failed for row {row['row_index']} after running out of retries\")\n",
    "    return {\n",
    "            \"row_index\": row[\"row_index\"],\n",
    "            \"predicted_age\": None,\n",
    "            \"confidence\": None,\n",
    "            \"explanation\": f\"⚠️ Failed after running out of retries\"\n",
    "        }"
   ],
   "id": "cba5f0de0b674f9a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from google import genai\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm import tqdm\n",
    "from time import sleep\n",
    "\n",
    "# Initialize client\n",
    "client = genai.Client()\n",
    "\n",
    "# Load your dataframe\n",
    "# rows = pd.read_csv(\"...\")\n",
    "\n",
    "predictions = []\n",
    "with ThreadPoolExecutor(max_workers=5) as executor:  # tune max_workers depending on limits\n",
    "    futures = {executor.submit(predict_single, row): row[\"row_index\"] for _, row in rows.iterrows()}\n",
    "    for future in tqdm(as_completed(futures), total=len(futures), desc=\"Predicting ages\"):\n",
    "        predictions.append(future.result())\n",
    "\n",
    "predicted_ages = pd.DataFrame(predictions)"
   ],
   "id": "ba76ef5129f07eb7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Going over the failed ones with Gemini 2.5 Pro",
   "id": "eba00ab407a8c005"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "failed = merged[merged.explanation.str.contains('⚠️')]\n",
    "failed_rows = rows[rows.row_index.isin(failed.row_index)]\n",
    "\n",
    "\n",
    "retrying_predictions = []\n",
    "with ThreadPoolExecutor(max_workers=5) as executor:  # tune max_workers depending on limits\n",
    "    futures = {executor.submit(predict_single, row, \"gemini-2.5-flash\"): row[\"row_index\"] for _, row in failed_rows.iterrows()}\n",
    "    for future in tqdm(as_completed(futures), total=len(futures), desc=\"Predicting ages\"):\n",
    "        retrying_predictions.append(future.result())\n",
    "\n",
    "retrying_predicted_ages = pd.DataFrame(retrying_predictions)\n",
    "# predicted_ages.to_csv('../data/data_for_report/llm_predicted_ages_v3.csv', index=False)"
   ],
   "id": "5680bf0ae13d517c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Merging the results and saving",
   "id": "6665c4cbc52d5b06"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Step 1: Set 'row_index' as the index for both DataFrames\n",
    "predicted_ages.set_index('row_index', inplace=True)\n",
    "retrying_predicted_ages.set_index('row_index', inplace=True)\n",
    "\n",
    "# Step 2: Replace rows in predicted_ages with those from retrying_predicted_ages\n",
    "predicted_ages.update(retrying_predicted_ages)\n",
    "\n",
    "# Step 3 (optional): Reset index if you want 'row_index' back as a column\n",
    "predicted_ages.reset_index(inplace=True)\n",
    "predicted_ages"
   ],
   "id": "5f7240220f8c7573",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "merged = predicted_ages.merge(ages, on='row_index')\n",
    "merged['difference'] = (merged['predicted_age'] - merged['d_age']).abs()\n",
    "merged.to_csv('../data/data_for_report/llm_predicted_ages_v3_with_diff.csv', index=False)"
   ],
   "id": "5748e3f2b98df70c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "merged.difference.describe()",
   "id": "aa7c7be24b6eba22",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Graphing",
   "id": "e1040cd9761b3dbd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Graph 1",
   "id": "f8d29528b72bb2d9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = px.scatter(\n",
    "    merged,\n",
    "    x=\"d_age\",                # Real age\n",
    "    y=\"predicted_age\",        # Predicted age\n",
    "    color=\"confidence\",       # Confidence as color\n",
    "    color_continuous_scale=\"Viridis\",\n",
    "    hover_data=[\"row_index\", \"difference\", \"explanation\"],\n",
    "    labels={\n",
    "        \"d_age\": \"Real Age\",\n",
    "        \"predicted_age\": \"Predicted Age\",\n",
    "        \"confidence\": \"Confidence (0-1)\"\n",
    "    },\n",
    "    title=\"Predicted Age vs Real Age with Confidence Coloring\"\n",
    ")\n",
    "\n",
    "# Add y = x line to indicate perfect predictions\n",
    "fig.add_shape(\n",
    "    type=\"line\",\n",
    "    x0=merged['d_age'].min(),\n",
    "    y0=merged['d_age'].min(),\n",
    "    x1=merged['d_age'].max(),\n",
    "    y1=merged['d_age'].max(),\n",
    "    line=dict(color=\"gray\", dash=\"dash\"),\n",
    "    name=\"Perfect Prediction Line\"\n",
    ")\n",
    "\n",
    "# Final layout tweaks\n",
    "fig.update_layout(\n",
    "    width=800,\n",
    "    height=600,\n",
    "    legend_title_text='Confidence',\n",
    "    coloraxis_colorbar=dict(title=\"Confidence\"),\n",
    "    xaxis=dict(title=\"Real Age\"),\n",
    "    yaxis=dict(title=\"Predicted Age\"),\n",
    ")\n",
    "\n",
    "fig.show()"
   ],
   "id": "54b8516fed6a0366",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Graph 2",
   "id": "fc628dd6aea2083e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig = px.scatter(\n",
    "    merged,\n",
    "    x=\"d_age\",\n",
    "    y=\"difference\",\n",
    "    color=\"confidence\",\n",
    "    color_continuous_scale=\"RdYlGn\",\n",
    "    hover_data=[\"predicted_age\", \"row_index\", \"confidence\"],\n",
    "    labels={\n",
    "        \"d_age\": \"Real Age\",\n",
    "        \"difference\": \"Prediction Error (Predicted - Real)\",\n",
    "        \"confidence\": \"Confidence\"\n",
    "    },\n",
    "    title=\"Prediction Error vs Real Age (Colored by Confidence)\"\n",
    ")\n",
    "\n",
    "fig.add_hline(y=0, line_dash=\"dash\", line_color=\"gray\")\n",
    "\n",
    "fig.update_layout(\n",
    "    height=600,\n",
    "    width=900,\n",
    "    xaxis_title=\"Real Age\",\n",
    "    yaxis_title=\"Prediction Error (years)\",\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ],
   "id": "5aceb086b648d808",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Playground",
   "id": "d0f8fecbeaab70ad"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# Creating a sample dataframe with the mentioned columns\n",
    "# This is just a dummy data for plot structure illustration\n",
    "# Replace this with actual dataframe if available\n",
    "\n",
    "data = {\n",
    "    'row_index': range(1, 101),\n",
    "    'predicted_age': [25 + (x % 10) for x in range(100)],\n",
    "    'confidence': [0.8 - (x % 15) * 0.02 for x in range(100)],\n",
    "    'explanation': ['Feature importance - X' for _ in range(100)],\n",
    "    'd_age': [24 + (x % 12) for x in range(100)],\n",
    "    'difference': [(25 + (x % 10)) - (24 + (x % 12)) for x in range(100)]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Adding mean age prediction for comparison (mean actual age as constant prediction)\n",
    "mean_age = df['d_age'].mean()\n",
    "df['mean_age_pred'] = mean_age\n",
    "\n",
    "# 1st plot: Scatter plot of predicted_age vs actual age (d_age) with confidence as color\n",
    "fig1 = px.scatter(df, x='d_age', y='predicted_age', color='confidence', title='Predicted Age vs Actual Age Colored by Confidence', labels={'d_age': 'Actual Age', 'predicted_age': 'Predicted Age'})\n",
    "\n",
    "# 2nd plot: Histogram of the error (difference)\n",
    "fig2 = px.histogram(df, x='difference', nbins=30, title='Distribution of Prediction Errors (Difference)', labels={'difference': 'Prediction Error (Predicted Age - Actual Age)'})\n",
    "\n",
    "# 3rd plot: Compare model prediction error vs mean age prediction error (absolute errors)\n",
    "df['abs_error_model'] = df['difference'].abs()\n",
    "df['abs_error_mean'] = (df['mean_age_pred'] - df['d_age']).abs()\n",
    "fig3 = px.scatter(df, x='abs_error_mean', y='abs_error_model', title='Comparison: Model Prediction Error vs Mean Age Prediction Error',\n",
    "                  labels={'abs_error_mean': 'Mean Age Prediction Error', 'abs_error_model': 'Model Prediction Error'},\n",
    "                  trendline='ols')\n",
    "\n",
    "fig1.show()\n",
    "fig2.show()\n",
    "fig3.show()"
   ],
   "id": "6ab146fcf2465b56",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "rows.columns.drop('Unnamed: 0')",
   "id": "85f16d7d106996a0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for start in tqdm(range(0, len(rows), BATCH_SIZE), desc=\"Predicting ages in batches\"):\n",
    "    batch = rows.iloc[start:start+BATCH_SIZE]\n",
    "    print(batch)"
   ],
   "id": "9a7898000848daf3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "batch",
   "id": "903c4b3244f58871",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "response = client.models.generate_content(\n",
    "        model=\"gemini-2.5-flash-lite\",\n",
    "        contents=create_batch_prompt(batch),\n",
    "        config={\"response_mime_type\": \"application/json\"},\n",
    "    )\n"
   ],
   "id": "9682a130c4496ee5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "response",
   "id": "809e36845800310f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "try:\n",
    "    batch_results = json.loads(response.text)\n",
    "except Exception as e:\n",
    "    print(f\"⚠️ Error parsing batch {start}: {e}\")\n",
    "\n",
    "for res in batch_results:\n",
    "    idx = res.get(\"row_index\")\n",
    "    print({\n",
    "        \"row_index\": idx,\n",
    "        \"predicted_age\": res.get(\"predicted_age\"),\n",
    "        \"real_age\": ages.loc[idx],\n",
    "        \"confidence\": res.get(\"confidence\"),\n",
    "        \"explanation\": res.get(\"explanation\"),\n",
    "    })\n"
   ],
   "id": "44ce2127e6c45375",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "batch_results = json.loads(response.text)",
   "id": "ab9be2aa1c1b08ae",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "batch_results[0]",
   "id": "bd486d025f46695d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for res in batch_results:\n",
    "    idx = res.get(\"row_index\")\n",
    "    print({\n",
    "        \"row_index\": idx,\n",
    "        \"predicted_age\": res.get(\"predicted_age\"),\n",
    "        \"real_age\": ages.loc[idx],\n",
    "        \"confidence\": res.get(\"confidence\"),\n",
    "        \"explanation\": res.get(\"explanation\"),\n",
    "    })"
   ],
   "id": "e9836565349ae908",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "rows",
   "id": "4672705b174b427a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "9869eacf35a5a052",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
